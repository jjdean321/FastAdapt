<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Fast Adaptation</title>
<style type="text/css">
<!--  body {-->
<!--  margin: 0  auto；-->
<!--  padding:10px 30px;-->
<!--  background: #fff;-->
<!--  color: #111;-->
<!--  font-size: 15px;-->
<!--  font-family: "Times New Roman", serif;-->
<!--  font-weight: 400;-->
<!--  line-height: 1.8;-->
<!--  -webkit-font-smoothing: antialiased;-->
<!--  }-->
<!--  }-->
  audio {
  width: 75%;
  height:30px;
  }
  img {
  width:100%;
  }
  video {
  width:75%;
  }
  html{
  height:100%;
  }
  body{
  margin: 0  auto；
  padding:10px 30px;
  background: #fff;
  color: #111;
  height:100%;
  font-size: 17px;
  font-family: "Times New Roman", serif;
  font-weight: 400;
  line-height: 1.8;
  overflow-x: hidden;
  -webkit-font-smoothing: antialiased;
  }
</style>
</head>
<div style="border: none; width:80%; margin: 0 auto;">
<body>
    <h2 align="center">Audio-visual End-to-end Multi-channel Speech Separation, Dereverberation and Recognition</h2>
</body>

<h3><a name="sectionIV">IV. Reference</a></h3>
<p> [1] J. Yu et al., “Audio-visual multi-channel recognition of overlapped speech,” in INTERSPEECH, 2020, pp. 3496–3500.</p>
<p> [2] G. Li et al., “Audio-visual multi-channel speech separation, dereverberation and recognition,” in ICASSP, 2022, pp. 6042–6046.</p>
<p> [3] J. Son Chung et al., “Lip reading sentences in the wild,” in IEEE Conf. Comput. Vis. Pattern Recognit., 2017, pp. 6447–6456. </p>
<p> [4] A. Gulati et al., “Conformer: Convolution-augmented transformer for speech recognition,” in INTERSPEECH, 2020, pp. 5036–5040</p>
  
</div>
</html>
